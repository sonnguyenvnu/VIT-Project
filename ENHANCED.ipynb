{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6673d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca2d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"YOUR_TRAIN_PATH\"\n",
    "train_raw = pd.read_csv(train_path, sep='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400bdbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = \"YOUR_VAL_PATH\"\n",
    "val_raw = pd.read_csv(val_path, sep='#')\n",
    "test_path = \"YOUR_TEST_PATH\"\n",
    "test_raw = pd.read_csv(test_path, sep='#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37085193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_elements(cpg):\n",
    "    elements_map = {}\n",
    "    elements_map['IDENTIFIER'] = []\n",
    "    elements_map['CALL'] = []\n",
    "    elements_map['CONTROL_STRUCTURE'] = []\n",
    "    if len(str(cpg)) > 100:\n",
    "        lines = cpg.split(\"--====--\")\n",
    "        elements = json.loads(lines[0]) \n",
    "        for e in elements:\n",
    "            if '_label' in e:\n",
    "                label = str(e['_label'])\n",
    "                if label == \"IDENTIFIER\":\n",
    "                    els = elements_map['IDENTIFIER']\n",
    "                    els.append(e)\n",
    "                    elements_map['IDENTIFIER'] = els\n",
    "                elif label == \"CALL\":\n",
    "                    els = elements_map['CALL']\n",
    "                    els.append(e)\n",
    "                    elements_map['CALL'] = els\n",
    "                elif label == \"CONTROL_STRUCTURE\":\n",
    "                    els = elements_map['CONTROL_STRUCTURE']\n",
    "                    els.append(e)\n",
    "                    elements_map['CONTROL_STRUCTURE'] = els\n",
    "    return elements_map\n",
    "\n",
    "cpg = test_raw['cpg'][6]\n",
    "mp = get_code_elements(cpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a66f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_analyzed_data(df):\n",
    "    result = pd.DataFrame(columns=[])\n",
    "    result['code'] = df['text']\n",
    "    types = ['dos', 'nan', 'info', 'overflow', 'priv', 'mem', 'exec', 'bypass']\n",
    "    for t in types:\n",
    "        result[t] = df[t]\n",
    "    element_col = []\n",
    "    for i in range(len(df)):\n",
    "        cpg = df['cpg'][i]\n",
    "        element_map = get_code_elements(cpg)\n",
    "        element_col.append(element_map)    \n",
    "    result['elements'] = element_col\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba985f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "  removed_cols = ['CVE Page', 'Summary', 'Vulnerability Classification',\n",
    "                  'codeLink', 'commit_id', 'commit_message', 'del_lines', 'file_name', 'func_before',\n",
    " 'vul_func_with_fix', 'flaw_line', 'flaw_line_index', 'vul_func_with_fix', 'processed_func',\n",
    " 'sql', 'r.spl.', 'dir.', 'trav.', 'http', 'xss', 'corr.']\n",
    "  \n",
    "  try:\n",
    "    df = df.rename({'func_before' : 'text', '+info': 'info', '+priv': 'priv', 'mem.' : 'mem'}, axis=1, inplace=False)\n",
    "  except:\n",
    "      print(\"RENAMED\")\n",
    "\n",
    "  for c in removed_cols:\n",
    "    try:\n",
    "      df = df.drop(c, axis=1)\n",
    "    except:\n",
    "      print(c)\n",
    "  df = df.drop('code', axis=1)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0963f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocess(train_raw)\n",
    "test_df = preprocess(test_raw)\n",
    "val_df = preprocess(val_raw)\n",
    "LABEL_COLUMNS = train_df.columns.tolist()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a8a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = construct_analyzed_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = construct_analyzed_data(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164fba57",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be2d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def code_tokenizer(identifier):\n",
    "    subtokens = set()\n",
    "    parts = filter(None, re.split(\"[, \\-!?:_~]+\", identifier))\n",
    "    for part in parts:\n",
    "        if not part.isdigit():\n",
    "            splitted = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', part)).split()\n",
    "            lower_tokens = [re.sub(\"[^a-zA-Z]+\", \"\", item.lower()) for item in splitted]\n",
    "            subtokens.update(set(lower_tokens))\n",
    "    return subtokens\n",
    "\n",
    "GLOBAL_SEP = \"---\"\n",
    "def code_call_tokenizer(call):\n",
    "    subtokens = set()\n",
    "    parts = re.split('\\.|\\>|\\:|\\-|\\<',call)\n",
    "    if len(parts) > 0:\n",
    "        funct = parts[len(parts)-1]\n",
    "        if not \" \" in funct:\n",
    "            subtokens.add(funct.replace(\"_\",\"\").lower())\n",
    "    return subtokens\n",
    "def code_raw_tokenizer(call):\n",
    "    subtokens = set()\n",
    "    call = call.replace(\"\\\\t\", \"\").replace(\"\\\\n\", \"\")\n",
    "    parts = re.split('\\.|\\>|\\:|\\-|\\<|\\(|\\)|\\\"|=|\\]|\\[|\\+|\\,| ',call)\n",
    "    if len(parts) > 0:\n",
    "        for code in parts:\n",
    "            if not \" \" in code:\n",
    "                splitted = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', code)).split()\n",
    "                lower_tokens = [item.lower().strip() for item in splitted]\n",
    "                subtokens.update(set(lower_tokens))\n",
    "    return subtokens\n",
    "\n",
    "def code_raw_control_tokenizer(con):\n",
    "    subtokens = set()\n",
    "    con = con.replace(\"\\\\t\", \"\").replace(\"\\\\n\", \"\").replace(\"&\", \"\").replace(\"!\", \"\").replace(\"|\", \"\")\n",
    "    parts = re.split('\\.|\\>|\\:|\\-|\\<|\\(|\\)|\\\"|=|\\]|\\[|\\+|\\,|\\!|\\&|\\|| ',con)\n",
    "    if len(parts) > 0:\n",
    "        for code in parts:\n",
    "            if not \" \" in code:\n",
    "                splitted = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', code)).split()\n",
    "                lower_tokens = [item.lower().strip() for item in splitted]\n",
    "                subtokens.update(set(lower_tokens))\n",
    "    return subtokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "identifier = 'file_system_indexer'\n",
    "code_tokenizer(identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9757d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(indx):\n",
    "    if indx == 0:\n",
    "        return 'dos'\n",
    "    if indx == 1:\n",
    "        return 'info'\n",
    "    if indx == 2:\n",
    "        return 'overflow'\n",
    "    if indx == 3:\n",
    "        return 'priv'\n",
    "    if indx == 4:\n",
    "        return 'mem'\n",
    "    if indx == 5:\n",
    "        return 'exec'\n",
    "    if indx == 6:\n",
    "        return 'bypass'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ad497e",
   "metadata": {},
   "source": [
    "# PREPARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e097bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractIdentifiers(idMap):\n",
    "    result = set()\n",
    "    for iden in idMap:\n",
    "        id_txt = str(iden['name'])\n",
    "        sub_tokens = code_tokenizer(id_txt)\n",
    "        result.update(sub_tokens)\n",
    "    return result\n",
    "\n",
    "def extractAllIdentifiers(df):\n",
    "    result = set()\n",
    "    id_col = []\n",
    "    for i in range(len(df)):\n",
    "        ids = extractIdentifiers(df['elements'][i]['IDENTIFIER'])\n",
    "        result.update(ids)\n",
    "        id_col.append(ids)\n",
    "    df['ids'] = id_col\n",
    "    return result\n",
    "\n",
    "def extractCalls(idMap):\n",
    "    result = set()\n",
    "    for iden in idMap:\n",
    "        call_txt = str(iden['name'])\n",
    "        sub_tokens = code_call_tokenizer(call_txt)\n",
    "        result.update(sub_tokens)\n",
    "    return result\n",
    "\n",
    "def extractAllCalls(df):\n",
    "    result = set()\n",
    "    call_col = []\n",
    "    for i in range(len(df)):\n",
    "        calls = extractCalls(df['elements'][i]['CALL'])\n",
    "        result.update(calls)\n",
    "        call_col.append(calls)\n",
    "    df['calls'] = call_col\n",
    "    return result\n",
    "\n",
    "def extractControls(idMap):\n",
    "    result = set()\n",
    "    for item in idMap:\n",
    "        call_txt = str(item['code'])\n",
    "        sub_tokens = code_raw_control_tokenizer(call_txt)\n",
    "        \n",
    "        result.update(sub_tokens)\n",
    "    return result\n",
    "\n",
    "def extractAllControls(df):\n",
    "    result = set()\n",
    "    control_col = []\n",
    "    for i in range(len(df)):\n",
    "        controls = extractControls(df['elements'][i]['CONTROL_STRUCTURE'])\n",
    "        result.update(controls)\n",
    "        control_col.append(controls)\n",
    "    df['controls'] = control_col\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TRAIN_IDENTIFIERS = extractAllIdentifiers(test)\n",
    "ALL_TEST_IDENTIFIERS = extractAllIdentifiers(test)\n",
    "ALL_TEST_CALLS = extractAllCalls(test)\n",
    "ALL_TRAIN_CALLS = extractAllCalls(test)\n",
    "ALL_TEST_CONTROLS = extractAllControls(test)\n",
    "ALL_TRAIN_CONTROLS = extractAllControls(test)\n",
    "train = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa26e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_TRAIN_IDENTIFIERS = ALL_TEST_IDENTIFIERS\n",
    "# ALL_TRAIN_CALLS = ALL_TEST_CALLS\n",
    "# ALL_TRAIN_CONTROLS = ALL_TEST_CONTROLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a447b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_THRESHOLD = YOUR_THRESHOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac63a4b",
   "metadata": {},
   "source": [
    "# IDENTIFIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_SEP = \"---\"\n",
    "\n",
    "def computeFreq(df, label, ALL_IDENTIFIERS):\n",
    "    items = df.loc[df[label] == 1]\n",
    "    id_freq = {}\n",
    "    for iden in ALL_IDENTIFIERS:\n",
    "        id_freq[iden] = 0\n",
    "        for ids in items['ids']:\n",
    "            if iden in ids:\n",
    "                id_freq[iden] = id_freq[iden]+1\n",
    "    for iden in ALL_IDENTIFIERS:\n",
    "        id_freq[iden] = 100*id_freq[iden]/len(id_freq)\n",
    "    return id_freq\n",
    "\n",
    "#target vs. others\n",
    "def freq_stat(freqs, target, ALL_IDENTIFIERS):\n",
    "    target_vs_others = {}\n",
    "    target_id_freq = freqs[target]\n",
    "    for iden in ALL_IDENTIFIERS:\n",
    "        rel_freq_target = target_id_freq[iden]\n",
    "        rel_freq_others = 0\n",
    "        for i in range(len(freqs)):\n",
    "            if i != target and freqs[i][iden] > rel_freq_others:\n",
    "                rel_freq_others = freqs[i][iden]\n",
    "        ratio = 0\n",
    "        if rel_freq_others != 0:\n",
    "            ratio = rel_freq_target/rel_freq_others\n",
    "        elif rel_freq_target != 0:\n",
    "            ratio = 1000\n",
    "        if ratio > FREQ_THRESHOLD:\n",
    "            target_vs_others[iden] = ratio\n",
    "    return sorted(target_vs_others.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def infreq_stat(freqs, target, ALL_IDENTIFIERS):\n",
    "    target_vs_others = {}\n",
    "    target_id_freq = freqs[target]\n",
    "    for iden in ALL_IDENTIFIERS:\n",
    "        rel_freq_target = target_id_freq[iden]\n",
    "        rel_freq_others = 10000\n",
    "        for i in range(len(freqs)):\n",
    "            if i != target and freqs[i][iden] < rel_freq_others:\n",
    "                rel_freq_others = freqs[i][iden]\n",
    "        ratio = 0\n",
    "        if rel_freq_others != 0 and rel_freq_target != 0:\n",
    "            ratio = rel_freq_others/rel_freq_target\n",
    "        elif rel_freq_others != 0:\n",
    "            ratio = 1000\n",
    "        if ratio > FREQ_THRESHOLD:\n",
    "            target_vs_others[iden] = ratio\n",
    "    return sorted(target_vs_others.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c15cf3f",
   "metadata": {},
   "source": [
    "# Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d1a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFreqCall(df, label, ALL_CALLS):\n",
    "    items = df.loc[df[label] == 1]\n",
    "    id_freq = {}\n",
    "    for iden in ALL_CALLS:\n",
    "        id_freq[iden] = 0\n",
    "        for ids in items['calls']:\n",
    "            if iden in ids:\n",
    "                id_freq[iden] = id_freq[iden]+1\n",
    "    for iden in ALL_CALLS:\n",
    "        id_freq[iden] = 100*id_freq[iden]/len(id_freq)\n",
    "    return id_freq\n",
    "\n",
    "def freq_call_stat(freqs, target, ALL_CALLS):\n",
    "    target_vs_others = {}\n",
    "    target_call_freq = freqs[target]\n",
    "    for call in ALL_CALLS:\n",
    "        rel_freq_target = target_call_freq[call]\n",
    "        rel_freq_others = 0\n",
    "        for i in range(len(freqs)):\n",
    "            if i != target and freqs[i][call] > rel_freq_others:\n",
    "                rel_freq_others = freqs[i][call]\n",
    "        rel_freq_others = rel_freq_others\n",
    "        ratio = 0\n",
    "        if rel_freq_others != 0:\n",
    "            ratio = rel_freq_target/rel_freq_others\n",
    "        elif rel_freq_target != 0:\n",
    "            ratio = 1000\n",
    "        if ratio > FREQ_THRESHOLD:\n",
    "            target_vs_others[call] = ratio\n",
    "    return sorted(target_vs_others.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def infreq_call_stat(freqs, target, ALL_CALLS):\n",
    "    target_vs_others = {}\n",
    "    target_call_freq = freqs[target]\n",
    "    for call in ALL_CALLS:\n",
    "        rel_freq_target = target_call_freq[call]\n",
    "        rel_freq_others = 1000\n",
    "        for i in range(len(freqs)):\n",
    "            if i != target and freqs[i][call] < rel_freq_others:\n",
    "                rel_freq_others = freqs[i][call]\n",
    "        ratio = 0\n",
    "        if rel_freq_others != 0 and rel_freq_target != 0:\n",
    "            ratio = rel_freq_others/rel_freq_target\n",
    "        elif rel_freq_others != 0:\n",
    "            ratio = 1000\n",
    "        if ratio > FREQ_THRESHOLD:\n",
    "            target_vs_others[call] = ratio\n",
    "    return sorted(target_vs_others.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b583e",
   "metadata": {},
   "source": [
    "# Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFreqControl(df, label, ALL_CONTROLS):\n",
    "    items = df.loc[df[label] == 1]\n",
    "    id_freq = {}\n",
    "    for iden in ALL_CONTROLS:\n",
    "        id_freq[iden] = 0\n",
    "        for ids in items['controls']:\n",
    "            if iden in ids:\n",
    "                id_freq[iden] = id_freq[iden]+1\n",
    "    for iden in ALL_CONTROLS:\n",
    "        id_freq[iden] = 100*id_freq[iden]/len(id_freq)\n",
    "    return id_freq\n",
    "\n",
    "def freq_control_stat(freqs, target, ALL_CONTROLS):\n",
    "    target_vs_others = {}\n",
    "    target_con_freq = freqs[target]\n",
    "    for con in ALL_CONTROLS:\n",
    "        rel_freq_target = target_con_freq[con]\n",
    "        rel_freq_others = 0\n",
    "        for i in range(len(freqs)):\n",
    "            if i != target and freqs[i][con] > rel_freq_others:\n",
    "                rel_freq_others = freqs[i][con]\n",
    "        rel_freq_others = rel_freq_others\n",
    "        ratio = 0\n",
    "        if rel_freq_others != 0:\n",
    "            ratio = rel_freq_target/rel_freq_others\n",
    "        elif rel_freq_target != 0:\n",
    "            ratio = 1000\n",
    "        if ratio > FREQ_THRESHOLD:\n",
    "            target_vs_others[con] = ratio\n",
    "    return sorted(target_vs_others.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "def infreq_control_stat(freqs, target, ALL_CONTROLS):\n",
    "    target_vs_others = {}\n",
    "    target_con_freq = freqs[target]\n",
    "    for con in ALL_CONTROLS:\n",
    "        rel_freq_target = target_con_freq[con]\n",
    "        rel_freq_others = 0\n",
    "        for i in range(len(freqs)):\n",
    "            if i != target and freqs[i][con] < rel_freq_others:\n",
    "                rel_freq_others = freqs[i][con]\n",
    "        ratio = 0\n",
    "        if rel_freq_others != 0 and rel_freq_target != 0:\n",
    "            ratio = rel_freq_others/rel_freq_target\n",
    "        elif rel_freq_others != 0:\n",
    "            ratio = 1000\n",
    "        if ratio > FREQ_THRESHOLD:\n",
    "            target_vs_others[con] = ratio\n",
    "    return sorted(target_vs_others.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b666b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train\n",
    "dos_id_freq_train = computeFreq(data, 'dos', ALL_TRAIN_IDENTIFIERS)\n",
    "info_id_freq_train = computeFreq(data, 'info', ALL_TRAIN_IDENTIFIERS)\n",
    "overflow_id_freq_train = computeFreq(data, 'overflow', ALL_TRAIN_IDENTIFIERS)\n",
    "priv_id_freq_train = computeFreq(data, 'priv', ALL_TRAIN_IDENTIFIERS)\n",
    "mem_id_freq_train = computeFreq(data, 'mem', ALL_TRAIN_IDENTIFIERS)\n",
    "exec_id_freq_train = computeFreq(data, 'exec', ALL_TRAIN_IDENTIFIERS)\n",
    "bypass_id_freq_train = computeFreq(data, 'bypass', ALL_TRAIN_IDENTIFIERS)\n",
    "\n",
    "freqs_train = [dos_id_freq_train, info_id_freq_train, overflow_id_freq_train, priv_id_freq_train, \n",
    "         mem_id_freq_train, exec_id_freq_train, bypass_id_freq_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8672df",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 2\n",
    "label = get_label(indx)\n",
    "sub_tokens_map = freq_stat(freqs_train, indx, ALL_TRAIN_IDENTIFIERS)\n",
    "sub_tokens_train = set()\n",
    "data = test\n",
    "for record in sub_tokens_map:\n",
    "    sub_tokens_train.add(record[0])\n",
    "\n",
    "test_tokens = data.loc[data[label] == 1]\n",
    "counter = 0\n",
    "for ids in test_tokens['ids']:\n",
    "    intersec = sub_tokens_train.intersection(ids)\n",
    "    if len(intersec) > 0:\n",
    "        counter = counter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772c9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c9476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_distinguishing_tokens(freqs, indx, all_calls):\n",
    "    sub_tokens_map = freq_stat(freqs, indx, all_calls)\n",
    "    sub_tokens_train = set()\n",
    "    for record in sub_tokens_map:\n",
    "        sub_tokens_train.add(record[0])\n",
    "    return sub_tokens_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinguishing_tokens_dos = extract_distinguishing_tokens(freqs_train, 0, ALL_TRAIN_IDENTIFIERS)\n",
    "# distinguishing_tokens_info = extract_distinguishing_tokens(freqs_train, 1, ALL_TRAIN_IDENTIFIERS)\n",
    "# distinguishing_tokens_overflow = extract_distinguishing_tokens(freqs_train, 2, ALL_TRAIN_IDENTIFIERS)\n",
    "# distinguishing_tokens_priv = extract_distinguishing_tokens(freqs_train, 3, ALL_TRAIN_IDENTIFIERS)\n",
    "# distinguishing_tokens_mem = extract_distinguishing_tokens(freqs_train, 4, ALL_TRAIN_IDENTIFIERS)\n",
    "# distinguishing_tokens_exec = extract_distinguishing_tokens(freqs_train, 5, ALL_TRAIN_IDENTIFIERS)\n",
    "# distinguishing_tokens_bypass = extract_distinguishing_tokens(freqs_train, 6, ALL_TRAIN_IDENTIFIERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49abb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(distinguishing_tokens_exec.intersection(distinguishing_tokens_bypass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7775232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(distinguishing_tokens_dos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7db3d3",
   "metadata": {},
   "source": [
    "# FUNCTION CALLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad94409",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train\n",
    "dos_call_freq_train = computeFreqCall(data, 'dos', ALL_TRAIN_CALLS)\n",
    "info_call_freq_train = computeFreqCall(data, 'info', ALL_TRAIN_CALLS)\n",
    "overflow_call_freq_train = computeFreqCall(data, 'overflow', ALL_TRAIN_CALLS)\n",
    "priv_call_freq_train = computeFreqCall(data, 'priv', ALL_TRAIN_CALLS)\n",
    "mem_call_freq_train = computeFreqCall(data, 'mem', ALL_TRAIN_CALLS)\n",
    "exec_call_freq_train = computeFreqCall(data, 'exec', ALL_TRAIN_CALLS)\n",
    "bypass_call_freq_train = computeFreqCall(data, 'bypass', ALL_TRAIN_CALLS)\n",
    "\n",
    "freqs_call_train = [dos_call_freq_train, info_call_freq_train, overflow_call_freq_train, priv_call_freq_train, \n",
    "         mem_call_freq_train, exec_call_freq_train, bypass_call_freq_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fbdc0d",
   "metadata": {},
   "source": [
    "# CONTROL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579dabda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train\n",
    "dos_con_freq_train = computeFreqControl(data, 'dos', ALL_TRAIN_CONTROLS)\n",
    "info_con_freq_train = computeFreqControl(data, 'info', ALL_TRAIN_CONTROLS)\n",
    "overflow_con_freq_train = computeFreqControl(data, 'overflow', ALL_TRAIN_CONTROLS)\n",
    "priv_con_freq_train = computeFreqControl(data, 'priv', ALL_TRAIN_CONTROLS)\n",
    "mem_con_freq_train = computeFreqControl(data, 'mem', ALL_TRAIN_CONTROLS)\n",
    "exec_con_freq_train = computeFreqControl(data, 'exec', ALL_TRAIN_CONTROLS)\n",
    "bypass_con_freq_train = computeFreqControl(data, 'bypass', ALL_TRAIN_CONTROLS)\n",
    "\n",
    "freqs_con_train = [dos_con_freq_train, info_con_freq_train, overflow_con_freq_train, priv_con_freq_train, \n",
    "         mem_con_freq_train, exec_con_freq_train, bypass_con_freq_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd9e77e",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b4e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 6\n",
    "label = get_label(indx)\n",
    "sub_tokens_call_map = freq_call_stat(freqs_call_train, indx, ALL_TRAIN_CALLS)\n",
    "sub_tokens_id_map = freq_stat(freqs_train, indx, ALL_TRAIN_IDENTIFIERS)\n",
    "sub_tokens_con_map = freq_control_stat(freqs_con_train, indx, ALL_TRAIN_CONTROLS)\n",
    "sub_tokens_call_train = set()\n",
    "sub_tokens_id_train = set()\n",
    "sub_tokens_con_train = set()\n",
    "\n",
    "data = test\n",
    "for record in sub_tokens_call_map:\n",
    "    sub_tokens_call_train.add(record[0])\n",
    "\n",
    "for record in sub_tokens_id_map:\n",
    "    sub_tokens_id_train.add(record[0])\n",
    "\n",
    "for record in sub_tokens_con_map:\n",
    "    sub_tokens_con_train.add(record[0])\n",
    "\n",
    "test_tokens = data.loc[data[label] == 1]\n",
    "counter = 0\n",
    "for row in test_tokens.iterrows():\n",
    "    intersec_call = sub_tokens_call_train.intersection(row[1]['calls'])\n",
    "    intersec_id = sub_tokens_id_train.intersection(row[1]['ids'])\n",
    "    intersec_con = sub_tokens_con_train.intersection(row[1]['controls'])\n",
    "    if len(intersec_call) > 0 or len(intersec_id) or len(intersec_con) > 0:\n",
    "        counter = counter+1\n",
    "print(counter/len(test_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e4b3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label2(indx):\n",
    "    if indx == 0:\n",
    "        return 'dos'\n",
    "    if indx == 1:\n",
    "        return 'info'\n",
    "    if indx == 2:\n",
    "        return 'overflow'\n",
    "    if indx == 3:\n",
    "        return 'priv'\n",
    "    if indx == 4:\n",
    "        return 'mem'\n",
    "    if indx == 5:\n",
    "        return 'exec'\n",
    "    if indx == 6:\n",
    "        return 'bypass'\n",
    "ft_df = pd.DataFrame()\n",
    "for indx in range(7):\n",
    "    label = get_label2(indx)\n",
    "    sub_tokens_call_map = freq_call_stat(freqs_call_train, indx, ALL_TRAIN_CALLS)\n",
    "    sub_tokens_id_map = freq_stat(freqs_train, indx, ALL_TRAIN_IDENTIFIERS)\n",
    "    sub_tokens_con_map = freq_control_stat(freqs_con_train, indx, ALL_TRAIN_CONTROLS)\n",
    "    sub_tokens_call_train = set()\n",
    "    sub_tokens_id_train = set()\n",
    "    sub_tokens_con_train = set()\n",
    "    for record in sub_tokens_call_map:\n",
    "        sub_tokens_call_train.add(record[0])\n",
    "    for record in sub_tokens_id_map:\n",
    "        sub_tokens_id_train.add(record[0])\n",
    "    for record in sub_tokens_con_map:\n",
    "        sub_tokens_con_train.add(record[0])\n",
    "        \n",
    "    infeq_sub_tokens_call_map = infreq_call_stat(freqs_call_train, indx, ALL_TRAIN_CALLS)\n",
    "    infeq_sub_tokens_id_map = infreq_stat(freqs_train, indx, ALL_TRAIN_IDENTIFIERS)\n",
    "    infeq_sub_tokens_con_map = infreq_control_stat(freqs_con_train, indx, ALL_TRAIN_CONTROLS)\n",
    "    infeq_sub_tokens_call_train = set()\n",
    "    infeq_sub_tokens_id_train = set()\n",
    "    infeq_sub_tokens_con_train = set()\n",
    "    for record in infeq_sub_tokens_call_map:\n",
    "        infeq_sub_tokens_call_train.add(record[0])\n",
    "    for record in infeq_sub_tokens_id_map:\n",
    "        infeq_sub_tokens_id_train.add(record[0])\n",
    "    for record in infeq_sub_tokens_con_map:\n",
    "        infeq_sub_tokens_con_train.add(record[0])\n",
    "    \n",
    "    ft_df[label] = [sub_tokens_id_train,sub_tokens_call_train,sub_tokens_con_train, \n",
    "                    infeq_sub_tokens_id_train, infeq_sub_tokens_call_train, infeq_sub_tokens_con_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dc9469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq_stat(freqs_train, 1, ALL_TRAIN_IDENTIFIERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c3fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_df['info'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194b5434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_df.to_csv('features.csv',index=False, mode='a', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158ef722",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbcd648",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_preds = pd.read_csv('raw_preds.csv')\n",
    "labels = pd.read_csv('labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12980a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_COLUMNS = raw_preds.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b82d4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3f2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_score(preds, lbs):\n",
    "    sum_ratio = 0.0\n",
    "    for i, row in preds.iterrows():\n",
    "        upper = 0\n",
    "        lower = 0\n",
    "        ratio = 0.0\n",
    "        for lb in LABEL_COLUMNS:\n",
    "            logic_and = preds[lb][i] + lbs[lb][i]\n",
    "            if logic_and == 2:\n",
    "                upper = upper+1\n",
    "                lower = lower+1\n",
    "            if logic_and == 1:\n",
    "                lower = lower+1\n",
    "        if lower != 0:\n",
    "            ratio = upper/lower\n",
    "        sum_ratio = sum_ratio+ratio\n",
    "    return sum_ratio/len(preds)\n",
    "\n",
    "def accuracy(preds, lbs):\n",
    "    sum_ratio = 0.0\n",
    "    for i, row in preds.iterrows():\n",
    "        upper = 0\n",
    "        ratio = 0.0\n",
    "        for lb in LABEL_COLUMNS:\n",
    "            if preds[lb][i] == lbs[lb][i]:\n",
    "                upper = upper+1\n",
    "            ratio = upper/len(LABEL_COLUMNS)\n",
    "        sum_ratio = sum_ratio+ratio\n",
    "    return sum_ratio/len(preds)\n",
    "\n",
    "def exact_match(preds, lbs):\n",
    "    sum_ratio = 0.0\n",
    "    for i, row in preds.iterrows():\n",
    "        upper = 0\n",
    "        for lb in LABEL_COLUMNS:\n",
    "            if preds[lb][i] == lbs[lb][i]:\n",
    "                upper = upper+1\n",
    "        if upper == len(LABEL_COLUMNS):\n",
    "            sum_ratio = sum_ratio+1\n",
    "    return sum_ratio/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbf63c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREQ_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real(preds, df, threshold=0.3):\n",
    "    COUNTER = 0\n",
    "    CORRECT = 0\n",
    "    excl = {}\n",
    "    for lb in LABEL_COLUMNS:\n",
    "        for i in range(len(preds[lb])):\n",
    "            if preds[lb][i] >= threshold:\n",
    "                preds[lb][i] = 1\n",
    "            else:\n",
    "                preds[lb][i] = 0\n",
    "    for index, row in preds.iterrows():\n",
    "        for lb in set(LABEL_COLUMNS):\n",
    "            if lb in ft_df:\n",
    "                sub_tokens_id_train = ft_df[lb][0]\n",
    "                sub_tokens_call_train = ft_df[lb][1]\n",
    "                sub_tokens_con_train = ft_df[lb][2]\n",
    "                intersec_call = sub_tokens_call_train.intersection(df['calls'][index])\n",
    "                intersec_id = sub_tokens_id_train.intersection(df['ids'][index])\n",
    "                intersec_con = sub_tokens_con_train.intersection(df['controls'][index])\n",
    "                if preds[lb][index] == 0 and (len(intersec_id) > 0 and len(intersec_call) > 0):\n",
    "                    preds[lb][index] = 1\n",
    "                    COUNTER = COUNTER+1\n",
    "                    if labels[lb][index] == 1:\n",
    "                        CORRECT = CORRECT+1\n",
    "                \n",
    "                infreq_sub_tokens_id_train = ft_df[lb][3]\n",
    "                infreq_sub_tokens_call_train = ft_df[lb][4]\n",
    "                infreq_sub_tokens_con_train = ft_df[lb][5]\n",
    "                infreq_intersec_call = infreq_sub_tokens_call_train.intersection(df['calls'][index])\n",
    "                infreq_intersec_id = infreq_sub_tokens_id_train.intersection(df['ids'][index])\n",
    "                infreq_intersec_con = infreq_sub_tokens_con_train.intersection(df['controls'][index])\n",
    "                if preds[lb][index] == 1 and (len(infreq_intersec_call) > 0 and len(infreq_intersec_id) > 0 and len(infreq_intersec_con) > 0):\n",
    "                    preds[lb][index] = 0\n",
    "                    COUNTER = COUNTER+1\n",
    "                    if labels[lb][index] == 0:\n",
    "                        CORRECT = CORRECT+1\n",
    "    print(COUNTER)\n",
    "    print(CORRECT/COUNTER)\n",
    "#CodeBERT\n",
    "preds = pd.read_csv('VIT_OUTPUT')\n",
    "\n",
    "THRESHOLD = YOUR_THRESHOLD\n",
    "real(preds, test, THRESHOLD)\n",
    "print(\"exact_match: \"+str(exact_match(preds, labels)))\n",
    "print(\"hamming_score: \"+ str(hamming_score(preds, labels)))\n",
    "print(\"accuracy: \"+str(accuracy(preds, labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5257afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "# preds = pd.read_csv('raw_preds.csv')\n",
    "real(preds, test, THRESHOLD)\n",
    "y_pred = preds.to_numpy()\n",
    "y_true = labels.to_numpy()\n",
    "print(classification_report(\n",
    "  y_true, \n",
    "  y_pred, \n",
    "  target_names=LABEL_COLUMNS, \n",
    "  zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff41079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
